export const news = [
    {
        title: 'How computer scientists and marketers can create a better CX with AI',
        img: '/assets/img_section3/cxai.png',
        minidesc:"Researchers from Erasmus University, The Ohio State University, York University, and London Business School published a new paper in the Journal of Marketing that examines the tension between AI's benefits and costs and then offers recommendations to guide managers and scholars investigating these challenges.", 
        desc:'The study, forthcoming in the Journal of Marketing, is titled "Consumers and Artificial Intelligence: An Experiential Perspective" and is authored by Stefano Puntoni, Rebecca Walker Reczek, Markus Giesler, and Simona Botti.<br>Not long ago, artificial intelligence (AI) was the stuff of science fiction. Now it is changing how consumers eat, sleep, work, play, and even date. Consumers can interact with AI throughout the day, from Fitbit\'s fitness tracker and Alibaba\'s Tmall Genie smart speaker to Google Photos editing suggestions and Spotify\'s music playlists. Given the growing ubiquity of AI in consumers\' lives, marketers operate in organizations with a culture increasingly shaped by computer science. Software developers\' objective of creating technical excellence, however, may not naturally align with marketers\' objective of creating valued consumer experiences. For example, computer scientists often characterize algorithms as neutral tools evaluated on efficiency and accuracy, an approach that may overlook the social and individual complexities of the contexts in which AI is increasingly deployed. Thus, whereas AI can improve consumers\' lives in very concrete and relevant ways, a failure to incorporate behavioral insight into technological developments may undermine consumers\' experiences with AI.<br>This article seeks to bridge these two perspectives. On one hand, the researchers acknowledge the benefits that AI can provide to consumers. On the other hand, they build on and integrate sociological and psychological scholarship to examine the costs consumers can experience in their interactions with AI. As Puntoni explains, "A key problem with optimistic celebrations that view AI\'s alleged accuracy and efficiency as automatic promoters of democracy and human inclusion is their tendency to efface intersectional complexities.<br>The article begins by presenting a framework that conceptualizes AI as an ecosystem with four capabilities: data capture, classification, delegation, and social. It focuses on the consumer experience of these capabilities, including the tensions felt. Reczek adds, "To articulate a customer-centric view of AI, we move attention away from the technology toward how the AI capabilities are experienced by consumers. Consumer experience relates to the interactions between the consumer and the company during the customer journey and encompasses multiple dimensions: emotional, cognitive, behavioral, sensorial, and social.<br>The researchers then discuss the experience of these tensions at a macro level, by exposing relevant and often explosive narratives in the sociological context, and at the micro level, by illustrating them with real-life examples grounded in relevant psychological literature. Using these insights, the researchers provide marketers with recommendations regarding how to learn about and manage the tensions. Paralleling the joint emphasis on social and individual responses, they outline both the organizational learning in which firms should engage to lead the deployment of consumer AI and concrete steps to design improved consumer AI experiences. The article closes with a research agenda that cuts across the four consumer experiences and ideas for how researchers might contribute new knowledge on this important topic.',
        views:'1872',
        date:'3 Days ago'


    },{
        title: 'Applying artificial intelligence to science educationl',
        img: '/assets/img_section3/AiEd.png',
        minidesc:"A new review published in the Journal of Research in Science Teaching highlights the potential of machine learning -- a subset of artificial intelligence -- in science education.", 
        desc:'Based on a review of 47 studies, investigators developed a framework to conceptualize machine learning applications in science assessment. The article aims to examine how machine learning has revolutionized the capacity of science assessment in terms of tapping into complex constructs, improving assessment functionality, and facilitating scoring automaticity.<br>Based on their investigation, the researchers identified various ways in which machine learning has transformed traditional science assessment, as well as anticipated impacts that it will likely have in the future (such as providing personalized science learning and changing the process of educational decision-making).<br> "Machine learning is increasingly impacting every aspect of our lives, including education," said lead author Xiaoming Zhai, an assistant professor in the University of Georgia\'s Mary Frances Early\'s Department of Mathematics and Science Education. "It is anticipated that the cutting-edge technology may be able to redefine science assessment practices and significantly change education in the future."',
        views:'2000',
        date:'1 week ago'


    },{
        title: 'How mobile apps grab our attention',
        img: '/assets/img_section3/mobApps.png/',
        minidesc:"First empirical study on how users pay visual attention to mobile app designs shows larger and brighter elements don't catch our eyes after all.", 
        desc:'Previous work on what attracts visual attention, or visual saliency, has centered on desktop and web-interfaces.<br> Apps appear differently on a phone than on a desktop computer or browser: they\'re on a smaller screen which simply fits fewer elements and, instead of a horizontal view, mobile devices typically use a vertical layout. Until now it was unclear how these factors would affect how apps actually attract our eyes, explains Aalto University Professor Antti Oulasvirta.<br>In the study, the research team used a large set of representative mobile interfaces and eye tracking to see how users look at screenshots of mobile apps, for both Android and Apple iOS devices.<br>According to previous thinking, our eyes should not only jump to bigger or brighter elements, but also stay there longer. Previous studies have also concluded that when we look at certain kinds of images, our attention is drawn to the centre of screens and also spread horizontally across the screen, rather than vertically. The researchers found these principles to have little effect on mobile interfaces.<br>It actually came as a surprise that bright colours didn\'t affect how people fixate on app details. One possible reason is that the mobile interface itself is full of glossy and colourful elements, so everything on the screen can potentially catch your attention -- it\'s just how they\'re designed. It seems that when everything is made to stand out, nothing pops out in the end, says lead author and Post-doctoral Researcher Luis Leiva.<br>The study also confirms that some other design principles hold true for mobile apps. Gaze, for example, drifts to the top-left corner, as an indication of exploration or scanning. Text plays an important role, likely due to its role in relaying information; on first use, users thus tend to focus on text elements of a mobile app as parts of icons, labels and logos.<br>Image elements drew visual attention more frequently than expected for the area they cover, though the average length of time users spent looking at images was similar to other app elements. Faces, too, attracted concentrated attention, though when accompanied by text, eyes wander much closer to the location of text.<br>Various factors influence where our visual attention goes. For photos, these factors include colour, edges, texture and motion. But when it comes to generated visual content, such as graphical user interfaces, design composition is a critical factor to consider, says Dr Hamed Tavakoli, who was also part of the Aalto University research team.<br>The study was completed with international collaborators including IIT Goa (India), Yildiz Technical University (Turkey) and Huawei Technologies (China). The team will present the findings on 6 October 2020 at MobileHCI\'20, the flagship conference on Human-Computer Interaction with mobile devices and services.',
        views:'786',
        date:'5 Hours ago'


    },{
        title: 'When bots do the negotiating, humans more likely to engage in deceptive techniques',
        img: '/assets/img_section3/negotiate.png/',
        minidesc:"Researchers found that whether humans would embrace a range of deceptive and sneaky negotiating techniques was dependent both on the humans' prior negotiating experience in negotiating as well as whether virtual agents where employed to negotiate on their behalf.", 
        desc:'Lead author of the paper on these studies, Johnathan Mell, says, "We want to understand the conditions under which people act deceptively, in some cases purely by giving them an artificial intelligence agent that can do their dirty work for them.".<br>Nowadays, virtual agents are employed nearly everywhere, from automated bidders on sites like eBay to virtual assistants on smart phones. One day, these agents could work on our behalf to negotiate the sale of a car, argue for a raise, or even resolve a legal dispute.<br>Mell, who conducted the research during his doctoral studies in computer science at USC, says, "Knowing how to design experiences and artificial agents which can act like some of the most devious among us is useful in learning how to combat those techniques in real life.".<br>The researchers are eager to understand how these virtual agents or bots might do our bidding and to understand how humans behave when deploying these agents on their behalf.<br>Gale Lucas, a research assistant professor in the Department of Computer Science at the USC Viterbi School of Engineering and at USC ICT, as well as the corresponding author on the study published in the Journal of Artificial Intelligence Research, says, "We wanted to predict how people are going to respond differently as this technology becomes available and gets to us more widely.".<br>The research team, consisting of Mell, Sharon Mozgai, Jonathan Gratch and Lucas, conducted three separate experiments, focusing on the conditions under which humans would opt for a range of ethically dubious behaviors. These behaviors included tough bargaining (aggressive pressuring), overt lies, information withholding, manipulative use of negative emotions (feigning anger), as well as rapport building and appealing through use of sympathy. Part of these experiments involved negotiations with non-human, virtual agents and programming virtual agents as their proxies.',
        views:'5065',
        date:'2 Weeks ago'


    },{
        title: 'The brain\'s memory abilities inspire AI experts in making neural networks less "forgetful"',
        img: '/assets/img_section3/brain.png',
        minidesc:"Artificial intelligence (AI) experts report that they have successfully addressed what they call a 'major, long-standing obstacle to increasing AI capabilities' by drawing inspiration from a human brain memory mechanism known as 'replay.'", 
        desc:'First author and postdoctoral researcher Gido van de Ven and principal investigator Andreas Tolias at Baylor, with Hava Siegelmann at UMass Amherst, write in Nature Communications that they have developed a new method to protect -- "surprisingly efficiently" -- deep neural networks from "catastrophic forgetting" -- upon learning new lessons, the networks forget what they had learned before.<br>Siegelmann and colleagues point out that deep neural networks are the main drivers behind recent AI advances, but progress is held back by this forgetting.<br>They write, "One solution would be to store previously encountered examples and revisit them when learning something new. Although such \'replay\' or \'rehearsal\' solves catastrophic forgetting," they add, "constantly retraining on all previously learned tasks is highly inefficient and the amount of data that would have to be stored becomes unmanageable quickly.".<br> Unlike AI neural networks, humans are able to continuously accumulate information throughout their life, building on earlier lessons. An important mechanism in the brain believed to protect memories against forgetting is the replay of neuronal activity patterns representing those memories, they explain.<br> Siegelmann says the team\'s major insight is in "recognizing that replay in the brain does not store data." Rather, "the brain generates representations of memories at a high, more abstract level with no need to generate detailed memories." Inspired by this, she and colleagues created an artificial brain-like replay, in which no data is stored. Instead, like the brain, the network generates high-level representations of what it has seen before.<br>The "abstract generative brain replay" proved extremely efficient, and the team showed that replaying just a few generated representations is sufficient to remember older memories while learning new ones. Generative replay not only prevents catastrophic forgetting and provides a new, more streamlined path for system learning, it allows the system to generalize learning from one situation to another, they state.<br>For example, "if our network with generative replay first learns to separate cats from dogs, and then to separate bears from foxes, it will also tell cats from foxes without specifically being trained to do so. And notably, the more the system learns, the better it becomes at learning new tasks," says van de Ven.<br>He and colleagues write, "We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network\'s own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks without storing data, and it provides a novel model for abstract level replay in the brain."\'Van de Ven says, "Our method makes several interesting predictions about the way replay might contribute to memory consolidation in the brain. We are already running an experiment to test some of these predictions.".',
        views:'490',
        date:'3 Hours ago'


    },{
        title: 'Medical robotic hand? Rubbery semiconductor makes it possible',
        img: '/assets/img_section3/medHand.png',
        minidesc:"A medical robotic hand could allow doctors to more accurately diagnose and treat people from halfway around the world, but currently available technologies aren't good enough to match the in-person experience.", 
        desc:'Researchers report in Science Advances that they have designed and produced a smart electronic skin and a medical robotic hand capable of assessing vital diagnostic data by using a newly invented rubbery semiconductor with high carrier mobility.<br>Cunjiang Yu, Bill D. Cook Associate Professor of Mechanical Engineering at the University of Houston and corresponding author for the work, said the rubbery semiconductor material also can be easily scaled for manufacturing, based upon assembly at the interface of air and water.<br>That interfacial assembly and the rubbery electronic devices described in the paper suggest a pathway toward soft, stretchy rubbery electronics and integrated systems that mimic the mechanical softness of biological tissues, suitable for a variety of emerging applications, said Yu, who also is a principal investigator at the Texas Center for Superconductivity at UH.<br>The smart skin and medical robotic hand are just two potential applications, created by the researchers to illustrate the discovery\'s utility.<br>In addition to Yu, authors on the paper include Ying-Shi Guan, Anish Thukral, Kyoseung Sim, Xu Wang, Yongcao Zhang, Faheem Ershad, Zhoulyu Rao, Fengjiao Pan and Peng Wang, all of whom are affiliated with UH. Co-authors Jianliang Xiao and Shun Zhang are affiliated with the University of Colorado.<br>Traditional semiconductors are brittle, and using them in otherwise stretchable electronics has required special mechanical accommodations. Previous stretchable semiconductors have had drawbacks of their own, including low carrier mobility -- the speed at which charge carriers can move through a material -- and complicated fabrication requirements.<br>Yu and collaborators last year reported that adding minute amounts of metallic carbon nanotubes to the rubbery semiconductor of P3HT -- polydimethylsiloxane composite -- improves carrier mobility, which governs the performances of semiconductor transistors.<br>Yu said the new scalable manufacturing method for these high performance stretchable semiconducting nanofilms and the development of fully rubbery transistors represent a significant step forward.<br> The production is simple, he said. A commercially available semiconductor material is dissolved in a solution and dropped on water, where it spreads; the chemical solvent evaporates from the solution, resulting in improved semiconductor properties.<br>It is a new way to create the high quality composite films, he said, allowing for consistent production of fully rubbery semiconductors.<br>Electrical performance is retained even when the semiconductor is stretched by 50%, the researchers reported. Yu said the ability to stretch the rubbery electronics by 50% without degrading the performance is a notable advance. Human skin, he said, can be stretched only about 30% without tearing.',
        views:'7981',
        date:'last Month'

    }
   ];

